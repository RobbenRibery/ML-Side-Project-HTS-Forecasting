{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys \n",
    "sys.path.insert(0, '../src/')\n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "from utils import * \n",
    "from hts.hierarchy import HierarchyTree \n",
    "from datetime import datetime \n",
    "import torch \n",
    "from proption_model import * \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_train_validation = pd.read_csv('../data/sales_train_validation.csv')\n",
    "sales_train_evaluation = pd.read_csv('../data/sales_train_evaluation.csv') \n",
    "calender = pd.read_csv('../data/calendar.csv') \n",
    "date_to_d = dict(zip(calender.date, calender.d)) \n",
    "d_to_date = dict(zip(calender.d, calender.date)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parent nodes sales "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1913,)\n"
     ]
    }
   ],
   "source": [
    "parent_sales = sales_train_validation[sales_train_validation.columns[6:]].sum(axis=0).values\n",
    "print(parent_sales.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time related covariates: \n",
    "\n",
    "- Wehther it is weekend/not, we observed sales are high overweekend across three categories "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "date = [d_to_date[d] for d in sales_train_validation.columns[6:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The statrting date is 2011-01-29\n",
      "The statrting date is 2016-04-24\n"
     ]
    }
   ],
   "source": [
    "print(f'The statrting date is {date[0]}')\n",
    "print(f'The statrting date is {date[-1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Given data is weekday.\n"
     ]
    }
   ],
   "source": [
    "d = datetime.strptime(date[2], '%Y-%m-%d')\n",
    "if d.weekday() > 4:\n",
    "    print ('Given date is weekend.')\n",
    "else:\n",
    "    print ('Given data is weekday.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d.weekday()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1913\n"
     ]
    }
   ],
   "source": [
    "weekend_binary = [1 if (datetime.strptime(d, '%Y-%m-%d')).weekday() > 4 else 0 for d in date]\n",
    "print(len(weekend_binary))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Proportions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1913, 30490)\n"
     ]
    }
   ],
   "source": [
    "stv = sales_train_validation[sales_train_validation.columns[6:]]\n",
    "stv = stv.T\n",
    "print(stv.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1913"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(stv.sum(axis=1).values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time series embeddings "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1913, 30490, 1])\n"
     ]
    }
   ],
   "source": [
    "hie_index = torch.arange(stv.shape[1])\n",
    "\n",
    "hie_index_2d = hie_index.expand(stv.shape[0], stv.shape[1])\n",
    "\n",
    "hie_index_3d = hie_index_2d.reshape(\n",
    "    hie_index_2d.shape[0], hie_index_2d.shape[-1], 1\n",
    ")\n",
    "\n",
    "print(hie_index_3d.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1913.0\n",
      "(1913, 30490, 1)\n",
      "torch.Size([1913, 30490, 1])\n"
     ]
    }
   ],
   "source": [
    "stv_proportions = np.divide(stv.values, stv.sum(axis=1).values.reshape(-1,1))\n",
    "print(stv_proportions.sum(axis=1).sum())\n",
    "\n",
    "stv_proportions_3d = stv_proportions.reshape(stv_proportions.shape[0], stv_proportions.shape[1], 1)\n",
    "print(stv_proportions_3d.shape)\n",
    "\n",
    "proportions_tensor = torch.tensor(stv_proportions_3d)\n",
    "print(proportions_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1913, 30490, 1])\n",
      "tensor([1])\n",
      "tensor([0])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "weekend_binary_tensor = torch.tensor(weekend_binary).unsqueeze_(-1).unsqueeze_(-1)\n",
    "weekend_binary_tensor = weekend_binary_tensor.expand(stv_proportions.shape[0], stv_proportions.shape[1], weekend_binary_tensor.shape[-1])\n",
    "print(weekend_binary_tensor.shape)\n",
    "print(weekend_binary_tensor[1,0])\n",
    "print(weekend_binary_tensor[2,0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1913, 30490, 1])\n"
     ]
    }
   ],
   "source": [
    "parent_sales_tensor = torch.tensor(parent_sales).unsqueeze_(-1).unsqueeze_(-1)\n",
    "parent_sales_tensor = parent_sales_tensor.expand(stv_proportions.shape[0], stv_proportions.shape[1], parent_sales_tensor.shape[-1])\n",
    "print(parent_sales_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1913, 30490, 4])\n"
     ]
    }
   ],
   "source": [
    "data_3d = torch.cat((proportions_tensor, parent_sales_tensor,weekend_binary_tensor, hie_index_3d), -1)\n",
    "data_3d = data_3d.double()\n",
    "print(data_3d.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1858, 56, 30490, 4])\n",
      "torch.Size([56, 30490, 4])\n",
      "data correctly processed to generate time-bacted tensor\n",
      "torch.Size([1858, 28, 30490, 4])\n",
      "torch.Size([1858, 28, 30490, 1])\n",
      "Entering the training pipeline\n",
      "torch.Size([1858, 28, 30490, 4])\n",
      "torch.Size([1858, 28, 30490, 1])\n"
     ]
    }
   ],
   "source": [
    "# dimension about the dataset\n",
    "no_child = proportions_tensor.shape[1]\n",
    "History = 28\n",
    "Forward = 28\n",
    "\n",
    "number_observations = data_3d.shape[0] - (History + Forward) + 1\n",
    "\n",
    "data_3d_time_batched = torch.empty(\n",
    "    number_observations, History + Forward, data_3d.shape[1], data_3d.shape[2]\n",
    ")\n",
    "\n",
    "for i in range(number_observations):\n",
    "\n",
    "    data_3d_time_batched[i, :, :, :] = data_3d[i : i + History + Forward, :, :]\n",
    "\n",
    "print(data_3d_time_batched.shape)\n",
    "print(data_3d_time_batched[-1,:,:,:].shape)\n",
    "\n",
    "\n",
    "#if torch.equal(data_3d_time_batched[-1, -1, :, :].double(), data_3d[-1, :, :].double()):\n",
    "\n",
    "print(\"data correctly processed to generate time-bacted tensor\")\n",
    "\n",
    "input_tensor = torch.empty(\n",
    "    number_observations,\n",
    "    History,\n",
    "    data_3d_time_batched.shape[-2],\n",
    "    data_3d_time_batched.shape[-1],\n",
    ")\n",
    "\n",
    "## We first use the recursive predicitng mechanism in LSTM, in the future we release more blocks that adapt to teacher-forcing/mixed training\n",
    "target_tensor = torch.empty(\n",
    "    number_observations,\n",
    "    Forward,\n",
    "    data_3d_time_batched.shape[-2],\n",
    "    1\n",
    "    # data_3d_time_batched.shape[-1]\n",
    ")\n",
    "\n",
    "print(input_tensor.shape)\n",
    "print(target_tensor.shape)\n",
    "\n",
    "print(\"Entering the training pipeline\")\n",
    "\n",
    "for i in range(data_3d_time_batched.shape[0]):\n",
    "\n",
    "    input_tensor[i] = data_3d_time_batched[i, :History, :, :]\n",
    "    target_2d = data_3d_time_batched[i, History:, :, 0]\n",
    "    target_tensor[i] = target_2d.reshape(\n",
    "        target_2d.shape[0], target_2d.shape[1], 1\n",
    "    )\n",
    "\n",
    "    # print(input_tensor.shape)\n",
    "    # print(target_tensor.shape)\n",
    "\n",
    "print(input_tensor.shape)\n",
    "print(target_tensor.shape)\n",
    "    # print(target_tensor[-1,0,:,:].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/50 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "input.size(-1) must be equal to input_size. Expected 12, got 11",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/Users/ericliu/Desktop/ML-Side Project/TS Forecasting/Kaggle - M5 - Sales Forecating (accuracy)/notebook/feature_generation.ipynb Cell 21\u001b[0m in \u001b[0;36m<cell line: 42>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ericliu/Desktop/ML-Side%20Project/TS%20Forecasting/Kaggle%20-%20M5%20-%20Sales%20Forecating%20%28accuracy%29/notebook/feature_generation.ipynb#ch0000028?line=38'>39</a>\u001b[0m l_r \u001b[39m=\u001b[39m \u001b[39m0.00079\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ericliu/Desktop/ML-Side%20Project/TS%20Forecasting/Kaggle%20-%20M5%20-%20Sales%20Forecating%20%28accuracy%29/notebook/feature_generation.ipynb#ch0000028?line=40'>41</a>\u001b[0m \u001b[39m# start training\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/ericliu/Desktop/ML-Side%20Project/TS%20Forecasting/Kaggle%20-%20M5%20-%20Sales%20Forecating%20%28accuracy%29/notebook/feature_generation.ipynb#ch0000028?line=41'>42</a>\u001b[0m p_model\u001b[39m.\u001b[39;49mtrain(\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ericliu/Desktop/ML-Side%20Project/TS%20Forecasting/Kaggle%20-%20M5%20-%20Sales%20Forecating%20%28accuracy%29/notebook/feature_generation.ipynb#ch0000028?line=42'>43</a>\u001b[0m     input_tensor,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ericliu/Desktop/ML-Side%20Project/TS%20Forecasting/Kaggle%20-%20M5%20-%20Sales%20Forecating%20%28accuracy%29/notebook/feature_generation.ipynb#ch0000028?line=43'>44</a>\u001b[0m     target_tensor,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ericliu/Desktop/ML-Side%20Project/TS%20Forecasting/Kaggle%20-%20M5%20-%20Sales%20Forecating%20%28accuracy%29/notebook/feature_generation.ipynb#ch0000028?line=44'>45</a>\u001b[0m     n_epochs,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ericliu/Desktop/ML-Side%20Project/TS%20Forecasting/Kaggle%20-%20M5%20-%20Sales%20Forecating%20%28accuracy%29/notebook/feature_generation.ipynb#ch0000028?line=45'>46</a>\u001b[0m     target_len,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ericliu/Desktop/ML-Side%20Project/TS%20Forecasting/Kaggle%20-%20M5%20-%20Sales%20Forecating%20%28accuracy%29/notebook/feature_generation.ipynb#ch0000028?line=46'>47</a>\u001b[0m     batch_size,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ericliu/Desktop/ML-Side%20Project/TS%20Forecasting/Kaggle%20-%20M5%20-%20Sales%20Forecating%20%28accuracy%29/notebook/feature_generation.ipynb#ch0000028?line=47'>48</a>\u001b[0m     learning_rate\u001b[39m=\u001b[39;49ml_r,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ericliu/Desktop/ML-Side%20Project/TS%20Forecasting/Kaggle%20-%20M5%20-%20Sales%20Forecating%20%28accuracy%29/notebook/feature_generation.ipynb#ch0000028?line=48'>49</a>\u001b[0m )\n",
      "File \u001b[0;32m~/Desktop/ML-Side Project/TS Forecasting/Kaggle - M5 - Sales Forecating (accuracy)/src/proption_model.py:425\u001b[0m, in \u001b[0;36mproportion_model.train\u001b[0;34m(self, input_tensor, target_tensor, n_epochs, target_len, batch_size, learning_rate)\u001b[0m\n\u001b[1;32m    418\u001b[0m \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m cat((\u001b[39minput\u001b[39m, embedd_vector), \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m    419\u001b[0m \u001b[39m# print(f\"with ENCODED hierachy, input batch diemsion is {input.shape}\")\u001b[39;00m\n\u001b[1;32m    420\u001b[0m \n\u001b[1;32m    421\u001b[0m \u001b[39m## ------------ lstm encoder ---input: L, C, input_dim ---------- ##\u001b[39;00m\n\u001b[1;32m    422\u001b[0m encoder_ouput, (\n\u001b[1;32m    423\u001b[0m     encoder_hn,\n\u001b[1;32m    424\u001b[0m     encoder_cn,\n\u001b[0;32m--> 425\u001b[0m ) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mencoder_lstm\u001b[39m.\u001b[39;49mforward(\u001b[39minput\u001b[39;49m, h0, c0)\n\u001b[1;32m    426\u001b[0m encoder_cache \u001b[39m=\u001b[39m (encoder_hn, encoder_cn)\n\u001b[1;32m    427\u001b[0m \u001b[39m# print(f\"The encoder final hidden state shape is {encoder_hn.shape}\")\u001b[39;00m\n\u001b[1;32m    428\u001b[0m \u001b[39m# print(f\"The encoder final cell state shape is {encoder_hn.shape}\")\u001b[39;00m\n\u001b[1;32m    429\u001b[0m \n\u001b[1;32m    430\u001b[0m \u001b[39m## ------------- lstm ddecoder --------L, C, input_dim ----------- ##\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/ML-Side Project/TS Forecasting/Kaggle - M5 - Sales Forecating (accuracy)/src/proption_model.py:119\u001b[0m, in \u001b[0;36mencoder_lstm.forward\u001b[0;34m(self, x, h0, c0)\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x, h0, c0):\n\u001b[1;32m    110\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    111\u001b[0m \u001b[39m    : param x :                    input of shape (# in batch, seq_len, lstm_input_dim)\u001b[39;00m\n\u001b[1;32m    112\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[39m    :                              element in the sequence\u001b[39;00m\n\u001b[1;32m    117\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 119\u001b[0m     encoder_ouptut, (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhn, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcn) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlstm(x, (h0, c0))\n\u001b[1;32m    120\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcache \u001b[39m=\u001b[39m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhn, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcn)\n\u001b[1;32m    122\u001b[0m     \u001b[39mreturn\u001b[39;00m encoder_ouptut, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcache\n",
      "File \u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1111\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/torch/nn/modules/rnn.py:759\u001b[0m, in \u001b[0;36mLSTM.forward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    755\u001b[0m     \u001b[39m# Each batch of the hidden state should match the input sequence that\u001b[39;00m\n\u001b[1;32m    756\u001b[0m     \u001b[39m# the user believes he/she is passing in.\u001b[39;00m\n\u001b[1;32m    757\u001b[0m     hx \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpermute_hidden(hx, sorted_indices)\n\u001b[0;32m--> 759\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcheck_forward_args(\u001b[39minput\u001b[39;49m, hx, batch_sizes)\n\u001b[1;32m    760\u001b[0m \u001b[39mif\u001b[39;00m batch_sizes \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    761\u001b[0m     result \u001b[39m=\u001b[39m _VF\u001b[39m.\u001b[39mlstm(\u001b[39minput\u001b[39m, hx, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_flat_weights, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbias, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_layers,\n\u001b[1;32m    762\u001b[0m                       \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropout, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbidirectional, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbatch_first)\n",
      "File \u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/torch/nn/modules/rnn.py:684\u001b[0m, in \u001b[0;36mLSTM.check_forward_args\u001b[0;34m(self, input, hidden, batch_sizes)\u001b[0m\n\u001b[1;32m    679\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcheck_forward_args\u001b[39m(\u001b[39mself\u001b[39m,  \u001b[39m# type: ignore[override]\u001b[39;00m\n\u001b[1;32m    680\u001b[0m                        \u001b[39minput\u001b[39m: Tensor,\n\u001b[1;32m    681\u001b[0m                        hidden: Tuple[Tensor, Tensor],\n\u001b[1;32m    682\u001b[0m                        batch_sizes: Optional[Tensor],\n\u001b[1;32m    683\u001b[0m                        ):\n\u001b[0;32m--> 684\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcheck_input(\u001b[39minput\u001b[39;49m, batch_sizes)\n\u001b[1;32m    685\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcheck_hidden_size(hidden[\u001b[39m0\u001b[39m], \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_expected_hidden_size(\u001b[39minput\u001b[39m, batch_sizes),\n\u001b[1;32m    686\u001b[0m                            \u001b[39m'\u001b[39m\u001b[39mExpected hidden[0] size \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m, got \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[1;32m    687\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcheck_hidden_size(hidden[\u001b[39m1\u001b[39m], \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_expected_cell_size(\u001b[39minput\u001b[39m, batch_sizes),\n\u001b[1;32m    688\u001b[0m                            \u001b[39m'\u001b[39m\u001b[39mExpected hidden[1] size \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m, got \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/torch/nn/modules/rnn.py:205\u001b[0m, in \u001b[0;36mRNNBase.check_input\u001b[0;34m(self, input, batch_sizes)\u001b[0m\n\u001b[1;32m    201\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\n\u001b[1;32m    202\u001b[0m         \u001b[39m'\u001b[39m\u001b[39minput must have \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m dimensions, got \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m    203\u001b[0m             expected_input_dim, \u001b[39minput\u001b[39m\u001b[39m.\u001b[39mdim()))\n\u001b[1;32m    204\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minput_size \u001b[39m!=\u001b[39m \u001b[39minput\u001b[39m\u001b[39m.\u001b[39msize(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m):\n\u001b[0;32m--> 205\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\n\u001b[1;32m    206\u001b[0m         \u001b[39m'\u001b[39m\u001b[39minput.size(-1) must be equal to input_size. Expected \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m, got \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m    207\u001b[0m             \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minput_size, \u001b[39minput\u001b[39m\u001b[39m.\u001b[39msize(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)))\n",
      "\u001b[0;31mRuntimeError\u001b[0m: input.size(-1) must be equal to input_size. Expected 12, got 11"
     ]
    }
   ],
   "source": [
    "###---------- dimension on the model hypter-parameters from the paper ------------ ######\n",
    "num_hts_embedd = no_child\n",
    "hts_embedd_dim = 8\n",
    "covariate_dim = 2 \n",
    "\n",
    "lstm_input_dim = 2 + covariate_dim + hts_embedd_dim\n",
    "lstm_hidden_dim = 48\n",
    "lstm_num_layer = 1\n",
    "lstm_output_dim = 64\n",
    "\n",
    "mha_embedd_dim = lstm_output_dim\n",
    "num_head = 4\n",
    "num_attention_layer = 1\n",
    "mha_output_dim = mha_embedd_dim\n",
    "residual_output_dim = mha_output_dim\n",
    "model_ouput_dim = 1\n",
    "\n",
    "# define the model object\n",
    "p_model = proportion_model(\n",
    "    num_hts_embedd,\n",
    "    hts_embedd_dim,  # ts embedding hyper pars\n",
    "    lstm_input_dim,\n",
    "    lstm_hidden_dim,\n",
    "    lstm_num_layer,\n",
    "    lstm_output_dim,  # lstm hyper pars\n",
    "    mha_embedd_dim,\n",
    "    num_head,\n",
    "    num_attention_layer,  # mha hyper pars\n",
    "    mha_output_dim,\n",
    "    residual_output_dim,  # skip connection hyper pars\n",
    "    model_ouput_dim,  # output later hyper pars\n",
    ")\n",
    "\n",
    "###---------- trainign parameters from the paper ------------ ######\n",
    "\n",
    "n_epochs = 50\n",
    "target_len = Forward\n",
    "batch_size = 4\n",
    "l_r = 0.00079\n",
    "\n",
    "# start training\n",
    "p_model.train(\n",
    "    input_tensor,\n",
    "    target_tensor,\n",
    "    n_epochs,\n",
    "    target_len,\n",
    "    batch_size,\n",
    "    learning_rate=l_r,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
